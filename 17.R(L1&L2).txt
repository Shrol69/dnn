import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt

# --------- New Synthetic Data ----------
X, y = make_classification(
    n_samples=1500,
    n_features=30,
    n_informative=15,
    n_redundant=5,
    n_repeated=2,
    n_classes=2,
    class_sep=1.5,
    flip_y=0.01,
    random_state=42
)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --------- Split ---------
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42
)

# --------- Model Builder ----------
def build_model(regularizer=None, use_dropout=False, input_shape=(30,)):
    model = Sequential()
    model.add(Dense(64, activation='relu', kernel_regularizer=regularizer, input_shape=input_shape))
    if use_dropout:
        model.add(Dropout(0.5))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# --------- Helper for Plotting ----------
def plot_history(history, title, early_stop_epoch=None):
    epochs = range(1, len(history.history['loss']) + 1)
    plt.figure(figsize=(12, 5))

    # Accuracy plot
    plt.subplot(1, 2, 1)
    plt.plot(epochs, history.history['accuracy'], label='Train Acc')
    plt.plot(epochs, history.history['val_accuracy'], label='Val Acc')
    if early_stop_epoch:
        plt.axvline(early_stop_epoch, color='r', linestyle='--', label=f'Stopped at {early_stop_epoch}')
    plt.title(f'{title} - Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    # Loss plot
    plt.subplot(1, 2, 2)
    plt.plot(epochs, history.history['loss'], label='Train Loss')
    plt.plot(epochs, history.history['val_loss'], label='Val Loss')
    if early_stop_epoch:
        plt.axvline(early_stop_epoch, color='r', linestyle='--', label=f'Stopped at {early_stop_epoch}')
    plt.title(f'{title} - Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# ========== 4. Addition of Noise ===========
noise_factor = 0.1
X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)
model_noise = build_model()
history_noise = model_noise.fit(X_train_noisy, y_train, epochs=100, validation_split=0.2, verbose=0)
plot_history(history_noise, 'Addition of Noise')

# ========== 5. Early Stopping ============
early_stop = EarlyStopping(patience=10, restore_best_weights=True)
model_early = build_model()
history_early = model_early.fit(
    X_train, y_train, epochs=100, validation_split=0.2,
    callbacks=[early_stop], verbose=0
)
plot_history(history_early, "Early Stopping", early_stop_epoch=early_stop.stopped_epoch)

# ========== 6. L1 Regularization ===========
model_l1 = build_model(regularizer=tf.keras.regularizers.l1(0.01))
history_l1 = model_l1.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=0)
plot_history(history_l1, "L1 Regularization")

# ========== 7. L2 Regularization ===========
model_l2 = build_model(regularizer=tf.keras.regularizers.l2(0.01))
history_l2 = model_l2.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=0)
plot_history(history_l2, "L2 Regularization")

# ========== 8. Dropout =====================
model_dropout = build_model(regularizer=None, use_dropout=True)
history_dropout = model_dropout.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=0)
plot_history(history_dropout, "Dropout")